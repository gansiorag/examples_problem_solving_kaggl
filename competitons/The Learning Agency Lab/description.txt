https://www.kaggle.com/competitions/pii-detection-removal-from-educational-data

Description
In today’s era of abundant educational data from sources such as ed tech, online learning, and research, widespread PII is a key challenge. PII’s presence is a barrier to analyze and create open datasets that advance education because releasing the data publicly puts students at risk. To reduce these risks, it’s crucial to screen and cleanse educational data for PII before public release, which data science could streamline.

Manually reviewing the entire dataset for PII is currently the most reliable screening method, but this results in significant costs and restricts the scalability of educational datasets. While techniques for automatic PII detection that rely on named entity recognition (NER) exist, these work best for PII that share common formatting such as emails and phone numbers. PII detection systems struggle to correctly label names and distinguish between names that are sensitive (e.g., a student's name) and those that are not (e.g., a cited author).

Competition host Vanderbilt University is a private research university in Nashville, Tennessee. It offers 70 undergraduate majors and a full range of graduate and professional degrees across 10 schools and colleges, all on a beautiful campus with state-of-the-art laboratories. Vanderbilt is optimized to inspire and nurture cross-disciplinary research that fosters groundbreaking discoveries.

For this competition, Vanderbilt has partnered with The Learning Agency Lab, an Arizona-based independent nonprofit focused on developing the science of learning-based tools and programs for the social good.

Your work in creating reliable automated techniques to detect PII will lead to more high-quality public educational datasets. Researchers can then tap into the potential of this previously unavailable data to develop effective tools and interventions that benefit both teachers and students.

Evaluation
Submissions are evaluated on micro Fβ
, which is a classification metric that assigns value to recall and precision. The value of β
 is set to 5, which means that recall is weighted 5 times more heavily than precision.

Submission File
For each document in the test set, you must predict which token values have a positive PII label. You should only include predictions of positive PII label values. Outside labels O should not be included. Each row in the submission should correspond to a single label found at a unique document-token pair. Additionally, the evaluation metric requires a row_id with an enumeration of predicted labels.

The file should contain a header and have the following format:

row_id,document,token,label
0,7,9,B-NAME_STUDENT
1,7,10,I-NAME_STUDENT
2,10,0,B-NAME_STUDENT
etc.

Timeline
January 17, 2024 - Start Date.
April 16, 2024 - Entry Deadline. You must accept the competition rules before this date in order to compete.
April 16, 2024 - Team Merger Deadline. This is the last day participants may join or merge teams.
April 23, 2024 - Final Submission Deadline.
All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.


Dataset Description
The competition dataset comprises approximately 22,000 essays written by students enrolled in a massively open online course. All of the essays were written in response to a single assignment prompt, which asked students to apply course material to a real-world problem. The goal of the competition is to annotate personally identifiable information (PII) found within the essays.

In order to protect student privacy, the original PII in the dataset has been replaced by surrogate identifiers of the same type using a partially automated process. A majority of the essays are reserved for the test set (70%), so competitors are encouraged to use external datasets that are publicly available to bolster the training data.

PII Types
The competition asks competitors to assign labels to the following seven types of PII:

NAME_STUDENT - The full or partial name of a student that is not necessarily the author of the essay. This excludes instructors, authors, and other person names.
EMAIL - A student’s email address.
USERNAME - A student's username on any platform.
ID_NUM - A number or sequence of characters that could be used to identify a student, such as a student ID or a social security number.
PHONE_NUM - A phone number associated with a student.
URL_PERSONAL - A URL that might be used to identify a student.
STREET_ADDRESS - A full or partial street address that is associated with the student, such as their home address.
File and Field Information
The data is presented in JSON format, which includes a document identifier, the full text of the essay, a list of tokens, information about whitespace, and token annotations. The documents were tokenized using the SpaCy English tokenizer.

Token labels are presented in BIO (Beginning, Inner, Outer) format. The PII type is prefixed with “B-” when it is the beginning of an entity. If the token is a continuation of an entity, it is prefixed with “I-”. Tokens that are not PII are labeled “O”.

{test|train}.json - the test and training data; the test data given on this page is for illustrative purposes only, and will be replaced during Code rerun with a hidden test set.

(int): the index of the essay
document (int): an integer ID of the essay
full_text (string): a UTF-8 representation of the essay
tokens (list)
(string): a string representation of each token
trailing_whitespace (list)
(bool): a boolean value indicating whether each token is followed by whitespace.
labels (list) [training data only]
(string): a token label in BIO format
sample_submission.csv - An example of the correct submission format. See the Submission File section of the Overview page for details.




